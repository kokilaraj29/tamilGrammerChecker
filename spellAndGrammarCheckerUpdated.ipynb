{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting indic-nlp-library\n",
      "  Downloading indic_nlp_library-0.92-py3-none-any.whl (40 kB)\n",
      "     -------------------------------------- 40.3/40.3 kB 112.9 kB/s eta 0:00:00\n",
      "Collecting sphinx-argparse\n",
      "  Downloading sphinx_argparse-0.5.2-py3-none-any.whl (12 kB)\n",
      "Collecting sphinx-rtd-theme\n",
      "  Downloading sphinx_rtd_theme-3.0.2-py2.py3-none-any.whl (7.7 MB)\n",
      "     ---------------------------------------- 7.7/7.7 MB 1.2 MB/s eta 0:00:00\n",
      "Collecting morfessor\n",
      "  Downloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from indic-nlp-library) (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from indic-nlp-library) (2.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->indic-nlp-library) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->indic-nlp-library) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->indic-nlp-library) (2024.2)\n",
      "Collecting sphinx>=5.1.0\n",
      "  Downloading sphinx-8.1.3-py3-none-any.whl (3.5 MB)\n",
      "     ---------------------------------------- 3.5/3.5 MB 1.4 MB/s eta 0:00:00\n",
      "Collecting docutils>=0.19\n",
      "  Downloading docutils-0.21.2-py3-none-any.whl (587 kB)\n",
      "     ------------------------------------ 587.4/587.4 kB 947.7 kB/s eta 0:00:00\n",
      "Collecting sphinxcontrib-jquery<5,>=4\n",
      "  Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n",
      "     -------------------------------------- 121.1/121.1 kB 1.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->indic-nlp-library) (1.17.0)\n",
      "Collecting sphinxcontrib-applehelp>=1.0.7\n",
      "  Downloading sphinxcontrib_applehelp-2.0.0-py3-none-any.whl (119 kB)\n",
      "     -------------------------------------- 119.3/119.3 kB 1.2 MB/s eta 0:00:00\n",
      "Collecting sphinxcontrib-devhelp>=1.0.6\n",
      "  Downloading sphinxcontrib_devhelp-2.0.0-py3-none-any.whl (82 kB)\n",
      "     ---------------------------------------- 82.5/82.5 kB 2.3 MB/s eta 0:00:00\n",
      "Collecting sphinxcontrib-htmlhelp>=2.0.6\n",
      "  Downloading sphinxcontrib_htmlhelp-2.1.0-py3-none-any.whl (98 kB)\n",
      "     ---------------------------------------- 98.7/98.7 kB 1.9 MB/s eta 0:00:00\n",
      "Collecting sphinxcontrib-jsmath>=1.0.1\n",
      "  Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\n",
      "Collecting sphinxcontrib-qthelp>=1.0.6\n",
      "  Downloading sphinxcontrib_qthelp-2.0.0-py3-none-any.whl (88 kB)\n",
      "     ---------------------------------------- 88.7/88.7 kB 1.2 MB/s eta 0:00:00\n",
      "Collecting sphinxcontrib-serializinghtml>=1.1.9\n",
      "  Downloading sphinxcontrib_serializinghtml-2.0.0-py3-none-any.whl (92 kB)\n",
      "     ---------------------------------------- 92.1/92.1 kB 1.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: Jinja2>=3.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.1.5)\n",
      "Requirement already satisfied: Pygments>=2.17 in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.18.0)\n",
      "Collecting snowballstemmer>=2.2\n",
      "  Downloading snowballstemmer-2.2.0-py2.py3-none-any.whl (93 kB)\n",
      "     ---------------------------------------- 93.0/93.0 kB 1.3 MB/s eta 0:00:00\n",
      "Collecting babel>=2.13\n",
      "  Downloading babel-2.16.0-py3-none-any.whl (9.6 MB)\n",
      "     ---------------------------------------- 9.6/9.6 MB 685.6 kB/s eta 0:00:00\n",
      "Collecting alabaster>=0.7.14\n",
      "  Downloading alabaster-1.0.0-py3-none-any.whl (13 kB)\n",
      "Collecting imagesize>=1.3\n",
      "  Downloading imagesize-1.4.1-py2.py3-none-any.whl (8.8 kB)\n",
      "Requirement already satisfied: requests>=2.30.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.32.3)\n",
      "Requirement already satisfied: packaging>=23.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (24.2)\n",
      "Requirement already satisfied: colorama>=0.4.6 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Jinja2>=3.1->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2024.12.14)\n",
      "Installing collected packages: snowballstemmer, morfessor, sphinxcontrib-serializinghtml, sphinxcontrib-qthelp, sphinxcontrib-jsmath, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, imagesize, docutils, babel, alabaster, sphinx, sphinxcontrib-jquery, sphinx-argparse, sphinx-rtd-theme, indic-nlp-library\n",
      "Successfully installed alabaster-1.0.0 babel-2.16.0 docutils-0.21.2 imagesize-1.4.1 indic-nlp-library-0.92 morfessor-2.0.6 snowballstemmer-2.2.0 sphinx-8.1.3 sphinx-argparse-0.5.2 sphinx-rtd-theme-3.0.2 sphinxcontrib-applehelp-2.0.0 sphinxcontrib-devhelp-2.0.0 sphinxcontrib-htmlhelp-2.1.0 sphinxcontrib-jquery-4.1 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-2.0.0 sphinxcontrib-serializinghtml-2.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install indic-nlp-library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-Levenshtein\n",
      "  Downloading python_Levenshtein-0.26.1-py3-none-any.whl (9.4 kB)\n",
      "Collecting Levenshtein==0.26.1\n",
      "  Downloading levenshtein-0.26.1-cp311-cp311-win_amd64.whl (98 kB)\n",
      "     -------------------------------------- 98.5/98.5 kB 235.4 kB/s eta 0:00:00\n",
      "Collecting rapidfuzz<4.0.0,>=3.9.0\n",
      "  Downloading rapidfuzz-3.11.0-cp311-cp311-win_amd64.whl (1.6 MB)\n",
      "     ---------------------------------------- 1.6/1.6 MB 780.8 kB/s eta 0:00:00\n",
      "Installing collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n",
      "Successfully installed Levenshtein-0.26.1 python-Levenshtein-0.26.1 rapidfuzz-3.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking sentence: நான் படம் படிக்கிறே\n",
      "\n",
      "Spell Check Suggestions:\n",
      "  படம்: பாடம், பாடம், பணம்\n",
      "  படிக்கிறே: படிக்கிறேன், படிக்க, அறிக்கை\n",
      "\n",
      "Grammar Check:\n",
      "Sentence does not match any known grammar rule.\n",
      "\n",
      "Corrected Sentence:\n",
      "நான் பாடம் படிக்கிறேன்.\n",
      "Checking sentence: அனைவருக்கும் நல்வாழ்துகள்.\n",
      "\n",
      "Spell Check Suggestions:\n",
      "  நல்வாழ்துகள்.: நல்வாழ்த்துகள், காத்து, வாழ்கை\n",
      "\n",
      "Grammar Check:\n",
      "Sentence does not match any known grammar rule.\n",
      "\n",
      "Corrected Sentence:\n",
      "அனைவருக்கும் நல்வாழ்த்துகள்.\n",
      "Checking sentence: தமிழின் மிக்க பழமயான மொழி வரலாற்றையும் பெருமையும் கொண்டது.\n",
      "\n",
      "Spell Check Suggestions:\n",
      "  பழமயான: பழமையான, பிரதான, இனிமையான\n",
      "  கொண்டது.: கொண்டது, காத்து, பொது\n",
      "\n",
      "Grammar Check:\n",
      "Sentence does not match any known grammar rule.\n",
      "\n",
      "Corrected Sentence:\n",
      "தமிழின் மிக்க பழமையான மொழி வரலாற்றையும் பெருமையும் கொண்டது.\n",
      "Checking sentence: இது உலகன் மிக அழகிய மற்றும் செம்மொழிகளில ஒன்றாகும்.\n",
      "\n",
      "Spell Check Suggestions:\n",
      "  உலகன்: உலகம், உலகம், உலகம்\n",
      "  செம்மொழிகளில: செம்மொழிகளில், செய்திகள், செய்திகள்\n",
      "  ஒன்றாகும்.: ஒன்றாகும், நாகம், மற்றும்\n",
      "\n",
      "Grammar Check:\n",
      "Sentence does not match any known grammar rule.\n",
      "\n",
      "Corrected Sentence:\n",
      "இது உலகம் மிக அழகிய மற்றும் செம்மொழிகளில் ஒன்றாகும்.\n",
      "Checking sentence: தமிழில் சொற்களை சரயாக எழுதுவதும், சரியான இடத்தில முறையாக பயன்படுத்துதும் மிகவும் முக்கியமானவை\n",
      "\n",
      "Spell Check Suggestions:\n",
      "  சரயாக: சரியாக, சரியான, சமயம்\n",
      "  எழுதுவதும்,: எழுதுவதும், எழுத்து, சுத்தம்\n",
      "  இடத்தில: இடத்தில், காத்து, ஒத்திகை\n",
      "  பயன்படுத்துதும்: பயன்படுத்துவதும், புத்தகம், சிந்தித்து\n",
      "\n",
      "Grammar Check:\n",
      "Sentence does not match any known grammar rule.\n",
      "\n",
      "Corrected Sentence:\n",
      "தமிழில் சொற்களை சரியாக எழுதுவதும் சரியான இடத்தில் முறையாக பயன்படுத்துவதும் மிகவும் முக்கியமானவை.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from difflib import get_close_matches\n",
    "from indicnlp.tokenize.sentence_tokenize import sentence_split\n",
    "from indicnlp.transliterate.unicode_transliterate import UnicodeIndicTransliterator\n",
    "from Levenshtein import distance\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "replacements = {\n",
    "    'அ': 'a', 'ஆ': 'aa', 'இ': 'i', 'ஈ': 'ii', 'உ': 'u', 'ஊ': 'uu',\n",
    "    'எ': 'e', 'ஏ': 'ee', 'ஐ': 'ai', 'ஒ': 'o', 'ஓ': 'oo', 'ஔ': 'au',\n",
    "    'க': 'k', 'ச': 's', 'ட': 't', 'த': 'th', 'ப': 'p', 'ற': 'r',\n",
    "    'ன': 'n', 'ந': 'n', 'ம': 'm', 'ய': 'y', 'ர': 'r', 'ல': 'l',\n",
    "    'வ': 'v', 'ழ': 'zh', 'ள': 'l', 'ஜ': 'j', 'ஷ': 'sh', 'ஸ': 's', 'ஹ': 'h'\n",
    "}\n",
    "\n",
    "def phonetic_encode(word):\n",
    "    encoded_word = \"\"\n",
    "    for char in word:\n",
    "        encoded_word += replacements.get(char, char)\n",
    "    return encoded_word\n",
    "\n",
    "def segment_syllables(word):\n",
    "    return list(word) \n",
    "\n",
    "def spell_checker(input_word, tamil_dictionary):\n",
    "    input_encoded = phonetic_encode(input_word)\n",
    "    dictionary_encoded = {word: phonetic_encode(word) for word in tamil_dictionary}\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        closest_matches = executor.map(\n",
    "            lambda word: (word, distance(input_encoded, dictionary_encoded[word])),\n",
    "            tamil_dictionary\n",
    "        )\n",
    "    \n",
    "    sorted_matches = sorted(closest_matches, key=lambda x: x[1])[:3]\n",
    "    return [match[0] for match in sorted_matches]\n",
    "\n",
    "def check_grammar(sentence):\n",
    "    GRAMMAR_RULES = {\n",
    "        \"simple_sentence\": (re.compile(r\"^(?:\\u0BA8\\u0BBE\\u0BA9\\u0BCD|\\u0BA8\\u0BC0|\\u0BAA\\u0B9F\\u0BAE\\u0BCD|\\u0BAE\\u0BB4\\u0BC8|\\u0BAE\\u0BB2\\u0BB0\\u0BCD|\\u0BAF\\u0BBE\\u0BB0\\u0BCD|\\u0BB0\\u0BAE\\u0BA9\\u0BCD)\\s+\\S+\\s+(?:\\u0B9A\\u0BC8\\u0BAF\\u0BCD\\u0B95\\u0BBF\\u0BB1\\u0BC7\\u0BA9\\u0BCD|\\u0B9A\\u0BC8\\u0BAF\\u0BCD\\u0B95\\u0BBF\\u0BB1\\u0BCB\\u0BA9\\u0BCD)\\.$\"), \"This is a simple sentence.\"),\n",
    "    }\n",
    "\n",
    "    for rule_name, (rule, message) in GRAMMAR_RULES.items():\n",
    "        if rule.match(sentence):\n",
    "            return f\"Sentence is grammatically correct. Rule matched: {rule_name} - {message}\"\n",
    "\n",
    "    return \"Sentence does not match any known grammar rule.\"\n",
    "\n",
    "def tokenize_sentences(paragraph):\n",
    "    return sentence_split(paragraph, lang='ta')\n",
    "\n",
    "def integrated_checker(sentence, tamil_dictionary):\n",
    "    sentence = UnicodeIndicTransliterator.transliterate(sentence, \"auto\", \"ta\")\n",
    "    words = sentence.split()\n",
    "    all_suggestions = {}\n",
    "    corrected_sentence = []\n",
    "\n",
    "    for word in words:\n",
    "        suggestions = spell_checker(word, tamil_dictionary)\n",
    "        if suggestions and word not in tamil_dictionary:\n",
    "            all_suggestions[word] = suggestions\n",
    "            corrected_sentence.append(suggestions[0])\n",
    "        else:\n",
    "            corrected_sentence.append(word)\n",
    "\n",
    "    corrected_sentence = \" \".join(corrected_sentence)\n",
    "\n",
    "    if not (corrected_sentence.endswith(\".\") or corrected_sentence.endswith(\"।\")):\n",
    "        corrected_sentence += \".\"\n",
    "\n",
    "    grammar_result = check_grammar(corrected_sentence)\n",
    "\n",
    "    return all_suggestions, grammar_result, corrected_sentence\n",
    "\n",
    "def load_tamil_dictionary(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        tamil_dictionary = [line.strip() for line in file]\n",
    "    return tamil_dictionary\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tamil_dictionary = load_tamil_dictionary(\"C:/Users/Admin/Desktop/dictionary.txt\")\n",
    "\n",
    "    sentences = [\n",
    "        \"நான் படம் படிக்கிறே\",\n",
    "        \"அனைவருக்கும் நல்வாழ்துகள். தமிழின் மிக்க பழமயான மொழி வரலாற்றையும் பெருமையும் கொண்டது. இது உலகன் மிக அழகிய மற்றும் செம்மொழிகளில ஒன்றாகும். தமிழில் சொற்களை சரயாக எழுதுவதும், சரியான இடத்தில முறையாக பயன்படுத்துதும் மிகவும் முக்கியமானவை\"\n",
    "    ]\n",
    "\n",
    "    for sentence in sentences:\n",
    "        segmented_sentences = tokenize_sentences(sentence)\n",
    "        for segmented_sentence in segmented_sentences:\n",
    "            print(f\"Checking sentence: {segmented_sentence}\")\n",
    "            spell_suggestions, grammar_check, corrected_sentence = integrated_checker(segmented_sentence, tamil_dictionary)\n",
    "\n",
    "            print(\"\\nSpell Check Suggestions:\")\n",
    "            for word, suggestions in spell_suggestions.items():\n",
    "                print(f\"  {word}: {', '.join(suggestions)}\")\n",
    "\n",
    "            print(\"\\nGrammar Check:\")\n",
    "            print(grammar_check)\n",
    "\n",
    "            print(\"\\nCorrected Sentence:\")\n",
    "            print(corrected_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
